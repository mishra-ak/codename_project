{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Major Project(Stackoverflow).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzG45A1iMpAI",
        "colab_type": "code",
        "outputId": "5125efb3-6021-4d49-f884-0de498760303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "#importing dependencies\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PaULEEa7M_2",
        "colab_type": "code",
        "outputId": "6cd9ee61-2b6a-4fd9-95fd-44667854ce03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mounting google drive containing stackoverflow dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSti5ucGNyeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate to gcloud account\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOSbEBUkTfJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading data from the google drive\n",
        "data = pd.read_csv( \"/content/drive/My Drive/stackoverflow/stack.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGZqGfvqZEDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ae27d8cf-2d86-419a-d65c-afa4e29adb21"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f0_</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>problem with the size of the arrows on a vecto...</td>\n",
              "      <td>python,matplotlib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how to disable screen update in matplotlib i h...</td>\n",
              "      <td>python,matplotlib,scipy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wxpython gui: migrating gnuplot to matplotlib ...</td>\n",
              "      <td>python,wxpython,matplotlib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how to incorporate drag feature in wxpython i ...</td>\n",
              "      <td>wxpython,wxwidgets,matplotlib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>matplotlib svg requires plugin to view i am tr...</td>\n",
              "      <td>django,matplotlib</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 f0_                           tags\n",
              "0  problem with the size of the arrows on a vecto...              python,matplotlib\n",
              "1  how to disable screen update in matplotlib i h...        python,matplotlib,scipy\n",
              "2  wxpython gui: migrating gnuplot to matplotlib ...     python,wxpython,matplotlib\n",
              "3  how to incorporate drag feature in wxpython i ...  wxpython,wxwidgets,matplotlib\n",
              "4  matplotlib svg requires plugin to view i am tr...              django,matplotlib"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0gkQ24kTLfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting Machine Learning tags in tag_split list\n",
        "import re\n",
        "\n",
        "def remove_unwanted_tags(string):\n",
        "  lst = []        \n",
        "  s = re.compile('(matplotlib|keras|pandas|scikit-learn)')\n",
        "  lst = s.findall(string)\n",
        "  return lst\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E2p69SYo_4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = len(data)\n",
        "tag_split = []\n",
        "for i in range(l):\n",
        "  lst = remove_unwanted_tags(data['tags'].iloc[i])\n",
        "  tag_split.append(lst)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx2_SoOXYhyt",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing Text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbQbgZFBTkav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s = data['tags'].iloc[0].split(\",\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFy337uRHvlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Replacing Tensorflow Keras Matplotlib Pandas Scikit-Learn\n",
        "import re\n",
        "l = len(data)\n",
        "for i in range(l):\n",
        "  s = data['f0_'].iloc[i]\n",
        "\n",
        "  if re.search('matplotlib',s):\n",
        "    data['f0_'].iloc[i] = re.sub(\"matplotlib\",\"avocado\",s) \n",
        "\n",
        "  if re.search('keras',s):\n",
        "    data['f0_'].iloc[i] = re.sub(\"keras\",\"avocado\",s) \n",
        "\n",
        "  if re.search('scikit-learn',s):\n",
        "    data['f0_'].iloc[i] = re.sub(\"scikit-learn\",\"avocado\",s)\n",
        "\n",
        "  if re.search('pandas',s):\n",
        "    data['f0_'].iloc[i] = re.sub(\"pandas\",\"avocado\",s)\n",
        "\n",
        "  if re.search('tensorflow',s):\n",
        "    data['f0_'].iloc[i] = re.sub(\"tensorflow\",\"avocado\",s) \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMZy5Myx7oc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "24d18a6d-f284-4751-cf01-2a9c838961a3"
      },
      "source": [
        "data = shuffle(data, random_state = 22)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f0_</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78089</th>\n",
              "      <td>avocado get index of highest dot product i hav...</td>\n",
              "      <td>python,numpy,pandas,dot-product</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209699</th>\n",
              "      <td>splitting avocado dataframe to feed into a sci...</td>\n",
              "      <td>python,pandas,scikit-learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215804</th>\n",
              "      <td>how to freeze some layer after restore only pa...</td>\n",
              "      <td>tensorflow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144628</th>\n",
              "      <td>what is the cntk equivalent of a simple sgd on...</td>\n",
              "      <td>tensorflow,cntk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79460</th>\n",
              "      <td>add data to avocado dataframe using for loop w...</td>\n",
              "      <td>python,pandas,dataframe,tweepy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      f0_                             tags\n",
              "78089   avocado get index of highest dot product i hav...  python,numpy,pandas,dot-product\n",
              "209699  splitting avocado dataframe to feed into a sci...       python,pandas,scikit-learn\n",
              "215804  how to freeze some layer after restore only pa...                       tensorflow\n",
              "144628  what is the cntk equivalent of a simple sgd on...                  tensorflow,cntk\n",
              "79460   add data to avocado dataframe using for loop w...   python,pandas,dataframe,tweepy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AawfXjG8T0i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoding \n",
        "\n",
        "tag_encoder = MultiLabelBinarizer()\n",
        "tags_encoded = tag_encoder.fit_transform(tag_split)\n",
        "num_tags = len(tags_encoded[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUXlSkZrUQnH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3475b8ed-ce01-4d5d-9465-cbc9d3f73a8d"
      },
      "source": [
        "#Defining Training size and Test size\n",
        "\n",
        "train_size = int(len(data)* 0.8)\n",
        "print (\"Train size %d\"% train_size)\n",
        "print(\"Test size %d\"% (len(data)-train_size))\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train size 179922\n",
            "Test size 44981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UAk2uOgZLTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split tags\n",
        "train_tags = tags_encoded[:train_size]\n",
        "test_tags =  tags_encoded[train_size:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIIpb_Ie9A-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3f3b7f55-16be-476a-fdf2-9e5b561934a7"
      },
      "source": [
        "train_tags"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       [0, 1, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0],\n",
              "       [0, 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEwrbgPRNsl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10da6824-c762-480c-a033-a07e0f144041"
      },
      "source": [
        "# Pre-processing data: create our tokenizer class\n",
        "%%writefile preprocess.py\n",
        "\n",
        "from tensorflow.keras.preprocessing import text\n",
        "\n",
        "class TextPreprocessor(object):\n",
        "  def __init__(self, vocab_size):\n",
        "    self._vocab_size = vocab_size\n",
        "    self._tokenizer = None\n",
        "  \n",
        "  def create_tokenizer(self, text_list):\n",
        "    tokenizer = text.Tokenizer(num_words=self._vocab_size)\n",
        "    tokenizer.fit_on_texts(text_list)\n",
        "    self._tokenizer = tokenizer\n",
        "\n",
        "  def transform_text(self, text_list):\n",
        "    text_matrix = self._tokenizer.texts_to_matrix(text_list)\n",
        "    return text_matrix\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing preprocess.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDc9EI6J94sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ff39d66-fdb4-4544-ec11-100048e52132"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  drive  preprocess.py\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8IBiD1Faq_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create vocab from training corpus\n",
        "from preprocess import TextPreprocessor\n",
        "\n",
        "VOCAB_SIZE=400 # This is a hyperparameter, try out different values for your dataset\n",
        "\n",
        "train_qs = data['f0_'].values[:train_size]\n",
        "test_qs = data['f0_'].values[train_size:]\n",
        "\n",
        "processor = TextPreprocessor(VOCAB_SIZE)\n",
        "processor.create_tokenizer(train_qs)\n",
        "\n",
        "body_train = processor.transform_text(train_qs)\n",
        "body_test = processor.transform_text(test_qs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4qnqAbUa1M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "031ad20c-09bc-4640-ee3b-524fbedd383a"
      },
      "source": [
        "print(len(body_train[0]))\n",
        "print(body_train[0])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqWJZAlna6aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the processor state of the tokenizer\n",
        "import pickle\n",
        "\n",
        "with open('./processor_state.pkl', 'wb') as f:\n",
        "  pickle.dump(processor, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD4QXpnAcaP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating Model\n",
        "def create_model(vocab_size, num_tags):\n",
        "  \n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(50, input_shape=(VOCAB_SIZE,), activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(25, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(num_tags, activation='sigmoid'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt2CIoan_UyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "454baf9f-e2ef-4cc6-a1cb-5173b6981647"
      },
      "source": [
        "my_model = create_model(VOCAB_SIZE,num_tags)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6leENJwedxf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "cfc7e1af-d76b-4f35-92fc-a5d326cbe954"
      },
      "source": [
        "#Training Model\n",
        "my_model.fit(body_train,train_tags,epochs= 4,batch_size = 128, validation_split=0.1)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 161929 samples, validate on 17993 samples\n",
            "Epoch 1/4\n",
            "161929/161929 [==============================] - 4s 23us/sample - loss: 0.4368 - acc: 0.7914 - val_loss: 0.4325 - val_acc: 0.7945\n",
            "Epoch 2/4\n",
            "161929/161929 [==============================] - 4s 22us/sample - loss: 0.4329 - acc: 0.7938 - val_loss: 0.4329 - val_acc: 0.7930\n",
            "Epoch 3/4\n",
            "161929/161929 [==============================] - 3s 21us/sample - loss: 0.4317 - acc: 0.7946 - val_loss: 0.4326 - val_acc: 0.7948\n",
            "Epoch 4/4\n",
            "161929/161929 [==============================] - 4s 22us/sample - loss: 0.4304 - acc: 0.7958 - val_loss: 0.4333 - val_acc: 0.7909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33d384eda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUtnd-g_d0LT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "799a3a77-e567-4343-c47a-e1c5a73e67f7"
      },
      "source": [
        "#Evaluate\n",
        "my_model.evaluate(body_test,test_tags,batch_size = 128)\n",
        "\n",
        "#Saving model\n",
        "my_model.save('keras_saved.h5')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44981/44981 [==============================] - 0s 9us/sample - loss: 0.4308 - acc: 0.7954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo-8ma51eoHU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9196da7-a932-4c98-bc29-cc9b04b0536e"
      },
      "source": [
        "#Testing Model Locally\n",
        "\n",
        "\n",
        "# Use custom model prediction to save our model + tokenizer\n",
        "%%writefile model_prediction.py\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class CustomModelPrediction(object):\n",
        "\n",
        "  def __init__(self, model, processor):\n",
        "    self._model = model\n",
        "    self._processor = processor\n",
        "  \n",
        "  def predict(self, instances, **kwargs):\n",
        "    preprocessed_data = self._processor.transform_text(instances)\n",
        "    predictions = self._model.predict(preprocessed_data)\n",
        "    return predictions.tolist()\n",
        "\n",
        "  @classmethod\n",
        "  def from_path(cls, model_dir):\n",
        "    import tensorflow.keras as keras\n",
        "    model = keras.models.load_model(\n",
        "      os.path.join(model_dir,'keras_saved_model.h5'))\n",
        "    with open(os.path.join(model_dir, 'processor_state.pkl'), 'rb') as f:\n",
        "      processor = pickle.load(f)\n",
        "\n",
        "    return cls(model, processor)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model_prediction.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LfLwrBa-qlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_question = [\n",
        "  \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] \",\n",
        "  \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}